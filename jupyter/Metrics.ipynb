{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics used in StyleGAN2\n",
    "    StyleGAN2 uses on Perceptual Path length same as StyleGAN\n",
    "Measure the pairwise distance https://github.com/richzhang/PerceptualSimilarity (pytorch original)\n",
    "\n",
    "https://github.com/alexlee-gk/lpips-tensorflow (tensorflow)\n",
    "   \n",
    "Zhang et al. 2018. *The Unreasonable Effectiveness of Deep Features as a Perceptual Metric* (https://arxiv.org/pdf/1801.03924.pdf)\n",
    "\n",
    "    distance is the sum of very small steps with epsilon in 1e-4\n",
    "    ../metrics/perceptual_path_length.py class PPL \n",
    "    crop face - downsample to 256x256 - compute distance\n",
    "   \n",
    "   **possible failure** hardcoded crop size\n",
    "    \n",
    "   **opportunity** why not segment face?: background is not important\n",
    "   \n",
    "    StyleGAN2 loads pretrained PPL tesorflow with VGG from\n",
    "http://d36zk2xti64re0.cloudfront.net/stylegan1/networks/metrics/vgg16_zhang_perceptual.pkl\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from metrics.metric_defaults import metric_defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics in https://arxiv.org/pdf/1912.04958.pdf\n",
    "\n",
    "\n",
    "\"Quantitative analysis of the quality of images producedusing  generative  methods  continues  to  be  a  challenging topic.  ***Frechet inception distance*** (FID) [20] measures differences  in  the  density  of  two  distributions  in  the  high-dimensional feature space of an InceptionV3 classifier [39].\n",
    "\n",
    "***Precision and Recall (P&R)*** [36, 27] provide additional visibility by explicitly quantifying the percentage of generated images that are similar to training data and the percentageof training data that can be generated, respectively.\n",
    "\n",
    "We use these metrics to quantify the improvements. Both FID and P&R are based on classifier networks that have recently been shown **to focus on textures rather than shapes [12]**, and consequently, the metrics do not accurately capture all aspects of image quality.\n",
    "\n",
    "We observe that the ***perceptual path length (PPL)*** metric [24], originally introduced as a method for estimating the quality of latent space interpolations,  correlates with consistency and stability of shapes. \n",
    "\n",
    "Based on this, we regularize the synthesis network to favor smooth mappings (Section 3) and achieve a clearimprovement in quality.  To counter its computational expense,  we  also  propose  executing  all  regularizations  less frequently,  observing  that  this  can  be  done  without  compromising effectiveness. \n",
    "\n",
    "Finally, we find that projection of images to the latent spaceWworks  significantly  better  with  the  new,  path-length regularized StyleGAN2 generator than with the original StyleGAN. This makes it easier to attribute a generated image to its source (Section 5).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid50k      \t metrics.frechet_inception_distance.FID\n",
      "is50k       \t metrics.inception_score.IS\n",
      "ppl_zfull   \t metrics.perceptual_path_length.PPL\n",
      "ppl_wfull   \t metrics.perceptual_path_length.PPL\n",
      "ppl_zend    \t metrics.perceptual_path_length.PPL\n",
      "ppl_wend    \t metrics.perceptual_path_length.PPL\n",
      "ppl2_wend   \t metrics.perceptual_path_length.PPL\n",
      "ls          \t metrics.linear_separability.LS\n",
      "pr50k3      \t metrics.precision_recall.PR\n"
     ]
    }
   ],
   "source": [
    "for metric in metric_defaults:\n",
    "    print(metric,\" \"*(10 - len(metric)), \"\\t\", metric_defaults[metric].func_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual Path Length\n",
    "    ./metrics/perceptual_path_length.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ppl_zfull',\n",
       " 'func_name': 'metrics.perceptual_path_length.PPL',\n",
       " 'num_samples': 50000,\n",
       " 'epsilon': 0.0001,\n",
       " 'space': 'z',\n",
       " 'sampling': 'full',\n",
       " 'crop': True,\n",
       " 'minibatch_per_gpu': 4,\n",
       " 'Gs_overrides': {'dtype': 'float32', 'mapping_dtype': 'float32'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_defaults['ppl_zfull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
